
# Context Engine Documentation


## Table of Contents


1. [Overview](#overview)

1. [Architecture](#architecture)

1. [Core Components](#core-components)

1. [API Reference](#api-reference)

1. [Getting Started](#getting-started)

1. [Advanced Usage](#advanced-usage)

1. [Configuration](#configuration)

1. [Performance & Optimization](#performance--optimization)

1. [Troubleshooting](#troubleshooting)

1. [Contributing](#contributing)


## Overview


### What is the Context Engine?


The Context Engine is the intelligent core of Context Sync that **eliminates the need for manual context management** in AI-assisted development. Instead of manually maintaining `.md` context files, the Context Engine automatically:


- **Extracts** relevant context from code changes, git commits, and conversations

- **Scores** context relevance using semantic similarity and structural analysis

- **Compresses** context to fit within AI token budgets while preserving key information

- **Monitors** context health and identifies gaps or redundancies

- **Watches** files in real-time for automatic context updates

### Why Do We Need the Context Engine?


#### The Problem

Modern AI coding assistants face several critical challenges:

1. **Context Overload**: Projects generate massive amounts of context (comments, docs, decisions, conversations)

1. **Manual Maintenance**: Developers spend time manually curating `.md` context files

1. **Stale Information**: Context files become outdated as code evolves

1. **Token Limitations**: AI models have strict token limits (8K, 32K, 128K tokens)

1. **Relevance Issues**: Not all context is equally important for the current task

1. **Information Gaps**: Important decisions and patterns get lost over time


#### The Solution

The Context Engine provides:


- **ðŸ¤– Automation**: Zero manual context management

- **ðŸŽ¯ Intelligence**: AI-powered relevance scoring and semantic understanding  

- **âš¡ Real-time**: Instant updates as code changes

- **ðŸ“Š Health Monitoring**: Proactive identification of context issues

- **ðŸ—œï¸ Smart Compression**: Optimal token usage with LLM-based summarization

- **ðŸ” Gap Detection**: Automated discovery of missing context areas

### Key Benefits


| Traditional Approach | Context Engine Approach |
|---------------------|------------------------|
| Manual `.md` files | Automatic extraction |
| Static, outdated context | Real-time, live updates |
| Generic relevance | AI-powered semantic scoring |
| Token waste | Intelligent compression |
| No visibility into quality | Comprehensive health monitoring |
| One-size-fits-all | Adaptive strategies |

## Architecture


The Context Engine follows a **modular, event-driven architecture** with five core components:

```text

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Context Autopilot                        â”‚
â”‚                    (Orchestration Layer)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Auto Extractor  â”‚  Relevance Scorer â”‚  Context Compressor      â”‚
â”‚  - File Watcher  â”‚  - Semantic AI    â”‚  - LLM Summarization    â”‚
â”‚  - Git Monitor   â”‚  - Embeddings     â”‚  - Smart Merging        â”‚
â”‚  - Pattern Det.  â”‚  - Structural     â”‚  - Token Management     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Health Monitor                              â”‚
â”‚              (Quality Assurance & Analytics)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```text


### Data Flow


```mermaid
graph TD
    A[File Changes] --> B[Auto Extractor]
    C[Git Commits] --> B
    D[Conversations] --> B
    
    B --> E[Context Items]
    E --> F[Relevance Scorer]
    F --> G[Scored Context]
    
    G --> H[Context Compressor] 
    H --> I[Optimized Context]
    
    I --> J[Health Monitor]
    J --> K[Health Reports]
    
    L[Autopilot] --> B
    L --> F  
    L --> H
    L --> J
```text


## Core Components


### 1. Auto Context Extractor


**Purpose**: Automatically extracts context from various sources without manual intervention.

**Key Features**:

- **Real-time File Watching**: Monitors file system changes with intelligent debouncing

- **Git Integration**: Extracts context from commits, diffs, and branch changes  

- **Pattern Detection**: Identifies architectural patterns and design decisions

- **Multi-source Support**: Handles code, documentation, comments, and conversations

- **Smart Filtering**: Ignores irrelevant files (`node_modules`, build artifacts)

**Core Methods**:
```typescript
// Watch entire directory
await extractor.watchDirectory('./src');

// Watch specific files
await extractor.watchFile('./package.json');

// Auto-discover and watch project
await extractor.autoWatchProject('./my-project');

// Extract from git commit
const contexts = await extractor.extractFromCommit(message, files, diff);

// Extract from file
const contexts = await extractor.extractFromFile('./src/api.ts');
```text


**Event System**:
```typescript
extractor.on('context-extracted', ({ contexts, source }) => {
  console.log(`Extracted ${contexts.length} contexts from ${source}`);
});

extractor.on('file-change-detected', ({ path, eventType }) => {
  console.log(`File ${path} was ${eventType}`);
});
```text


### 2. Relevance Scorer


**Purpose**: Intelligently scores context relevance using AI-powered semantic analysis.

**Key Features**:

- **OpenAI Embeddings Integration**: Advanced semantic similarity using `text-embedding-ada-002`

- **Multi-factor Scoring**: Combines semantic, structural, temporal, and frequency factors

- **Intelligent Fallback**: Graceful degradation to keyword matching when AI unavailable

- **Caching System**: Optimizes API calls and reduces costs

- **Confidence Metrics**: Provides reasoning for scoring decisions

**Scoring Factors**:
1. **Semantic Similarity** (40%): AI embeddings-based content similarity

1. **Structural Relevance** (30%): File and function overlap analysis

1. **Temporal Proximity** (15%): Recency and usage patterns  

1. **Frequency Score** (10%): How often context is accessed

1. **Causal Relationships** (5%): Dependency and call graph analysis


**Usage Example**:
```typescript
const scorer = createRelevanceScorer({
  apiKey: process.env.OPENAI_API_KEY
});

const scores = await scorer.scoreRelevance(contexts, {
  currentFiles: ['./src/api.ts', './src/auth.ts'],
  recentConversation: ['implement JWT auth', 'add rate limiting'],
  taskDescription: 'Add authentication middleware',
  activeKeywords: ['auth', 'jwt', 'middleware']
});

// Results include detailed scoring breakdown
scores.forEach(score => {
  console.log(`Context ${score.contextId}: ${score.score}/100`);
  console.log(`Factors: ${JSON.stringify(score.factors, null, 2)}`);
  console.log(`Reasoning: ${score.reasoning}`);
});
```text


### 3. Context Compressor


**Purpose**: Intelligently compresses context to fit within AI token budgets while preserving essential information.

**Key Features**:

- **LLM-powered Summarization**: Uses OpenAI GPT models for intelligent summarization

- **Multi-strategy Compression**: Aggressive, balanced, and conservative approaches

- **Smart Merging**: Combines similar contexts to reduce redundancy

- **Token Budget Management**: Precise control over final token count

- **Quality Preservation**: Maintains technical details and key decisions

**Compression Strategies**:

| Strategy | Target Reduction | Preserves | Use Case |
|----------|------------------|-----------|----------|
| `aggressive` | 70% | Critical decisions only | Very tight token budgets |
| `balanced` | 50% | Decisions + key patterns | Standard usage |
| `conservative` | 30% | Most content | Large token budgets |

**Usage Example**:
```typescript
const compressor = createContextCompressor({
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-3.5-turbo'
});

const result = await compressor.compress(scoredContexts, 4000, {
  name: 'balanced',
  targetReduction: 0.5,
  preserveTypes: ['decision', 'documentation']
});

console.log(`Compressed from ${result.original.length} to ${result.compressed.length} items`);
console.log(`Token reduction: ${result.tokensRemoved} tokens (${(result.compressionRatio * 100).toFixed(1)}%)`);
console.log(`Summary: ${result.summary}`);
```text


### 4. Health Monitor


**Purpose**: Continuously monitors context quality and provides actionable insights for improvement.

**Key Features**:

- **Coverage Analysis**: Identifies files and directories lacking context

- **Gap Detection**: Finds important files without adequate coverage

- **Redundancy Detection**: Locates duplicate or highly similar contexts

- **Staleness Monitoring**: Tracks context freshness and relevance decay

- **Conflict Detection**: Identifies contradictory information

- **Actionable Recommendations**: Provides specific improvement suggestions

**Health Metrics**:
```typescript
interface ContextHealth {
  score: number; // 0-100 overall health score
  metrics: {
    totalItems: number;
    freshItems: number;
    staleItems: number; 
    conflicts: number;
    coverage: number; // % of codebase with context
    avgRelevance: number;
  };
  issues: HealthIssue[];
  recommendations: string[];
}
```text


**Usage Example**:
```typescript
const monitor = createContextHealthMonitor('./my-project');
const health = await monitor.assessHealth(allContexts);

console.log(`Overall Health Score: ${health.score}/100`);
console.log(`Coverage: ${health.metrics.coverage}%`);

health.issues.forEach(issue => {
  console.log(`${issue.severity.toUpperCase()}: ${issue.description}`);
  console.log(`Suggestion: ${issue.suggestion}`);
});
```text


### 5. Context Autopilot


**Purpose**: Orchestrates all components for fully automatic context management.

**Key Features**:

- **Zero-configuration Operation**: Works out of the box with sensible defaults

- **Event-driven Architecture**: Responds to git changes, file modifications, and conversations

- **Health Monitoring**: Periodic assessment with proactive issue reporting

- **Resource Management**: Efficient cleanup and memory management

- **Flexible Configuration**: Customizable behavior for different project needs

**Configuration Options**:
```typescript
interface AutopilotConfig {
  maxContextTokens: number;        // Token budget (default: 8000)
  relevanceThreshold: number;      // Min relevance score (default: 40)
  autoExtractFromGit: boolean;     // Monitor git changes (default: true) 
  autoExtractFromConversations: boolean; // Monitor conversations (default: true)
  autoCompression: boolean;        // Auto-compress when needed (default: true)
  healthCheckInterval: number;     // Minutes between health checks (default: 60)
}
```text


**Complete Example**:
```typescript
const autopilot = createContextAutopilot('./my-project', {
  maxContextTokens: 12000,
  relevanceThreshold: 50,
  healthCheckInterval: 30
});

// Set up event listeners
autopilot.on('context-extracted', (data) => {
  console.log(`Auto-extracted context: ${data.source}`);
});

autopilot.on('health-warning', (health) => {
  console.log(`Health issue detected: Score ${health.score}/100`);
});

autopilot.on('context-compressed', (result) => {
  console.log(`Auto-compressed: ${result.compressionRatio * 100}% reduction`);
});

// Start autonomous operation
await autopilot.start();

// Get optimal context for current task
const context = await autopilot.getOptimalContext(
  ['./src/api.ts', './src/auth.ts'],
  ['How to implement JWT authentication?'],
  'Add secure user authentication'
);
```text


## API Reference


### Factory Functions


The Context Engine provides convenient factory functions for quick setup:

```typescript
// Individual components
const scorer = createRelevanceScorer(openaiConfig?);
const compressor = createContextCompressor(llmConfig?);
const extractor = createAutoContextExtractor();
const monitor = createContextHealthMonitor(workspacePath?);
const autopilot = createContextAutopilot(workspacePath, autopilotConfig?);

// Complete engine
const engine = createContextEngine(workspacePath, autopilotConfig?);
```text


### Core Interfaces


#### ContextItem

```typescript
interface ContextItem {
  id: string;
  type: 'decision' | 'conversation' | 'code' | 'file' | 'documentation';
  content: string;
  timestamp: Date;
  metadata: {
    project?: string;
    files?: string[];
    functions?: string[];
    keywords?: string[];
    author?: string;
  };
  tokens: number;
}
```text


#### RelevanceScore

```typescript
interface RelevanceScore {
  contextId: string;
  score: number; // 0-100
  factors: {
    recency: number;
    semantic: number;
    structural: number;
    frequency: number;
    causal: number;
  };
  reasoning: string;
  confidence: number;
}
```text


#### ExtractedContext

```typescript
interface ExtractedContext {
  type: 'code_change' | 'conversation' | 'decision' | 'documentation';
  source: string;
  content: string;
  confidence: number; // 0-100
  metadata: {
    files?: string[];
    functions?: string[];
    keywords?: string[];
    timestamp: Date;
  };
}
```text


## Getting Started


### Quick Start (5 minutes)


1. **Install Dependencies**:

```bash
npm install openai  # For AI features (optional)
```text


1. **Basic Setup**:

```typescript
import { createContextEngine } from './context-engine';

// Create engine for your project
const engine = createContextEngine('./my-project');

// Start autonomous context management  
await engine.autopilot.start();

// Get context for current task
const context = await engine.autopilot.getOptimalContext(
  ['./src/components/UserProfile.tsx'],
  ['How do I add a profile image upload feature?']
);

console.log('Relevant context:', context);
```text


1. **With OpenAI Integration**:

```typescript
import { createContextEngine } from './context-engine';

const engine = createContextEngine('./my-project', {
  // Enhanced with AI features
  maxContextTokens: 8000,
  relevanceThreshold: 60
});

// Configure AI components
engine.scorer = createRelevanceScorer({
  apiKey: process.env.OPENAI_API_KEY
});

engine.compressor = createContextCompressor({
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-3.5-turbo'
});

await engine.autopilot.start();
```text


### Integration Example


Here's how to integrate the Context Engine into an existing MCP server:

```typescript
import { createContextEngine } from './context-engine';

class MCPServerWithContextEngine {
  private engine: ReturnType<typeof createContextEngine>;
  
  constructor(workspacePath: string) {
    this.engine = createContextEngine(workspacePath, {
      maxContextTokens: 8000,
      autoExtractFromGit: true,
      healthCheckInterval: 60
    });
    
    this.setupEventHandlers();
  }
  
  async start() {
    await this.engine.autopilot.start();
    console.log('Context Engine started - autonomous context management active');
  }
  
  private setupEventHandlers() {
    this.engine.autopilot.on('context-extracted', (data) => {
      this.notifyClients('context-updated', data);
    });
    
    this.engine.autopilot.on('health-warning', (health) => {
      this.logWarning(`Context health issue: ${health.score}/100`);
    });
  }
  
  async getContextForQuery(query: string, currentFiles: string[]) {
    return await this.engine.autopilot.getOptimalContext(
      currentFiles,
      [query],
      query
    );
  }
}
```text


## Advanced Usage


### Custom Extraction Patterns


Add custom pattern detection for domain-specific contexts:

```typescript
class CustomExtractor extends AutoContextExtractor {
  async extractFromFile(filePath: string): Promise<ExtractedContext[]> {
    const contexts = await super.extractFromFile(filePath);
    
    // Add custom pattern detection
    if (filePath.includes('/api/')) {
      const apiContext = await this.extractAPIContext(filePath);
      contexts.push(...apiContext);
    }
    
    return contexts;
  }
  
  private async extractAPIContext(filePath: string): Promise<ExtractedContext[]> {
    // Custom logic for API endpoint documentation
    const content = await fs.readFile(filePath, 'utf-8');
    const endpoints = this.parseEndpoints(content);
    
    return endpoints.map(endpoint => ({
      type: 'documentation',
      source: filePath,
      content: `API Endpoint: ${endpoint.method} ${endpoint.path}\n${endpoint.description}`,
      confidence: 90,
      metadata: {
        files: [filePath],
        keywords: ['api', endpoint.method.toLowerCase(), ...endpoint.tags],
        timestamp: new Date()
      }
    }));
  }
}
```text


### Custom Compression Strategies


Implement domain-specific compression logic:

```typescript
class CustomCompressor extends ContextCompressor {
  async compress(items: any[], maxTokens: number, strategy: CompressionStrategy) {
    // Pre-process: Identify critical vs non-critical contexts
    const criticalItems = items.filter(item => 
      item.type === 'decision' || 
      item.metadata.files?.some(f => f.includes('/core/'))
    );
    
    const nonCriticalItems = items.filter(item => !criticalItems.includes(item));
    
    // Compress non-critical items more aggressively
    const compressedNonCritical = await super.compress(
      nonCriticalItems, 
      maxTokens * 0.3,
      { ...strategy, targetReduction: 0.8 }
    );
    
    const compressedCritical = await super.compress(
      criticalItems,
      maxTokens * 0.7,
      { ...strategy, targetReduction: 0.2 }
    );
    
    return {
      original: items,
      compressed: [...compressedCritical.compressed, ...compressedNonCritical.compressed],
      // ... other properties
    };
  }
}
```text


### Health Monitoring Webhooks


Set up proactive notifications for context health issues:

```typescript
const monitor = createContextHealthMonitor('./project');

monitor.on('health-critical', async (health) => {
  // Send alert to team
  await fetch('https://hooks.slack.com/your-webhook', {
    method: 'POST',
    body: JSON.stringify({
      text: `ðŸš¨ Context Health Alert: Score dropped to ${health.score}/100`,
      attachments: [{
        color: 'danger',
        fields: health.issues.map(issue => ({
          title: issue.type,
          value: issue.description,
          short: true
        }))
      }]
    })
  });
});

// Run health checks every 30 minutes
setInterval(async () => {
  const contexts = await loadAllContexts();
  const health = await monitor.assessHealth(contexts);
  
  if (health.score < 70) {
    monitor.emit('health-critical', health);
  }
}, 30 * 60 * 1000);
```text


## Configuration


### Environment Variables


The Context Engine respects these environment variables:

```bash
# OpenAI Configuration

OPENAI_API_KEY=sk-...                    # Required for AI features
OPENAI_API_URL=https://api.openai.com/v1 # Custom API endpoint
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
OPENAI_CHAT_MODEL=gpt-3.5-turbo

# Performance Settings  

CONTEXT_ENGINE_CACHE_SIZE=1000           # Max cached embeddings
CONTEXT_ENGINE_DEBOUNCE_MS=300           # File watcher debounce
CONTEXT_ENGINE_MAX_FILE_SIZE=1048576     # 1MB max file size

# Monitoring

CONTEXT_ENGINE_HEALTH_INTERVAL=3600      # Health check interval (seconds)
CONTEXT_ENGINE_LOG_LEVEL=info            # debug|info|warn|error
```text


### Project Configuration File


Create a `.context-engine.json` file in your project root:

```json
{
  "autopilot": {
    "maxContextTokens": 8000,
    "relevanceThreshold": 40,
    "autoExtractFromGit": true,
    "autoExtractFromConversations": true,
    "autoCompression": true,
    "healthCheckInterval": 60
  },
  "extraction": {
    "watchPatterns": ["src/**", "lib/**", "docs/**"],
    "ignorePatterns": ["node_modules/**", "dist/**", ".git/**"],
    "fileTypes": [".ts", ".tsx", ".js", ".jsx", ".md", ".py"]
  },
  "compression": {
    "defaultStrategy": "balanced",
    "preserveTypes": ["decision", "documentation"],
    "maxSummaryLength": 200
  },
  "health": {
    "coverageThreshold": 50,
    "stalenessThreshold": 7,
    "redundancySimilarity": 0.8
  }
}
```text


Load configuration:

```typescript
import config from './.context-engine.json';

const engine = createContextEngine('./project', config.autopilot);
```text


## Performance & Optimization


### Memory Management


The Context Engine includes several memory optimization features:

1. **LRU Caches**: Embeddings and summaries use least-recently-used eviction

1. **Lazy Loading**: Components are initialized only when needed  

1. **Streaming Processing**: Large files are processed in chunks

1. **Garbage Collection**: Automatic cleanup of stale cache entries


Monitor memory usage:

```typescript
const scorer = createRelevanceScorer();
const compressor = createContextCompressor();

// Check cache sizes
console.log('Embedding cache:', scorer.getCacheStats());
console.log('Summarization cache:', compressor.getCacheStats());

// Clear caches when needed
scorer.clearEmbeddingCache();
compressor.clearCache();
```text


### API Rate Limiting


For OpenAI API usage:

```typescript
const scorer = createRelevanceScorer({
  apiKey: process.env.OPENAI_API_KEY,
  // Built-in rate limiting
  maxRequestsPerMinute: 60,
  batchSize: 10
});
```text


### Performance Monitoring


Track Context Engine performance:

```typescript
const engine = createContextEngine('./project');

engine.autopilot.on('performance-stats', (stats) => {
  console.log(`Extraction time: ${stats.extractionMs}ms`);
  console.log(`Scoring time: ${stats.scoringMs}ms`);
  console.log(`Compression time: ${stats.compressionMs}ms`);
  console.log(`Memory usage: ${stats.memoryMB}MB`);
});
```text


## Troubleshooting


### Common Issues


#### 1. High Memory Usage

```typescript
// Solution: Configure cache limits
const scorer = createRelevanceScorer({
  maxCacheSize: 500  // Reduce cache size
});

// Monitor and clear caches periodically
setInterval(() => {
  const stats = scorer.getCacheStats();
  if (stats.size > 50 * 1024 * 1024) { // 50MB
    scorer.clearEmbeddingCache();
  }
}, 60000);
```text


#### 2. OpenAI API Errors

```typescript
const scorer = createRelevanceScorer({
  apiKey: process.env.OPENAI_API_KEY,
  retries: 3,
  timeoutMs: 30000
});

scorer.on('api-error', (error) => {
  console.error('OpenAI API error:', error);
  // Fallback to keyword matching
});
```text


#### 3. File Watcher Issues

```typescript
const extractor = createAutoContextExtractor();

extractor.on('error', (error) => {
  if (error.code === 'EMFILE') {
    console.error('Too many open files - reduce watch scope');
  }
});

// Limit watching scope
await extractor.watchDirectory('./src'); // Instead of entire project
```text


### Debug Mode


Enable detailed logging:

```typescript
process.env.CONTEXT_ENGINE_LOG_LEVEL = 'debug';

const engine = createContextEngine('./project');

engine.autopilot.on('debug', (event) => {
  console.log(`[DEBUG] ${event.component}: ${event.message}`, event.data);
});
```text


### Performance Profiling


```typescript
const engine = createContextEngine('./project');

// Enable performance monitoring
engine.autopilot.enableProfiling();

engine.autopilot.on('profile-report', (report) => {
  console.log('Performance Report:', {
    extraction: `${report.extraction.avg}ms avg, ${report.extraction.max}ms max`,
    scoring: `${report.scoring.avg}ms avg, ${report.scoring.max}ms max`,
    compression: `${report.compression.avg}ms avg, ${report.compression.max}ms max`
  });
});
```text


## Contributing


### Development Setup


1. **Clone and install**:

```bash
git clone https://github.com/yourusername/context-sync
cd context-sync
npm install
```text


1. **Set up environment**:

```bash
cp .env.example .env
# Add your OpenAI API key to .env

```text


1. **Run tests**:

```bash
npm test                    # Unit tests
npm run test:integration    # Integration tests
npm run test:performance    # Performance tests
```text


### Testing Guidelines


The Context Engine includes comprehensive test suites:

#### Unit Tests

```bash
# Test individual components

npm run test:unit -- src/context-engine/relevance-scorer.test.ts
npm run test:unit -- src/context-engine/context-compressor.test.ts
```text


#### Integration Tests  

```bash
# Test component interactions

npm run test:integration -- src/context-engine/autopilot.integration.test.ts
```text


#### Performance Tests

```bash
# Test with large codebases

npm run test:perf -- --project-size=large --files=10000
```text


### Code Style


The Context Engine follows strict TypeScript and code quality standards:

```bash
npm run lint                # ESLint + Prettier
npm run type-check         # TypeScript compilation
npm run test:coverage      # Coverage report (>90% required)
```text


### Adding New Features


1. **Create feature branch**: `git checkout -b feature/new-extraction-pattern`

1. **Add tests first**: Write comprehensive tests for new functionality

1. **Implement feature**: Follow existing patterns and interfaces

1. **Update docs**: Add documentation and examples

1. **Performance test**: Ensure no regressions

1. **Submit PR**: Include benchmarks and migration notes


### Component Architecture Guidelines


When adding new components:

1. **Extend EventEmitter**: All components should emit events for observability

1. **Implement Factory Pattern**: Provide `createComponentName()` factory functions  

1. **Add TypeScript Interfaces**: Define clear interfaces for all data structures

1. **Include Cache Management**: Implement memory-conscious caching where applicable

1. **Error Handling**: Graceful degradation and detailed error events

1. **Configuration**: Support both constructor options and environment variables


Example new component structure:

```typescript
// new-component.ts
import { EventEmitter } from 'events';

export interface NewComponentConfig {
  setting1: string;
  setting2?: number;
}

export interface NewComponentResult {
  data: any;
  confidence: number;
}

export class NewComponent extends EventEmitter {
  constructor(private config: NewComponentConfig) {
    super();
  }
  
  async process(input: any): Promise<NewComponentResult> {
    try {
      this.emit('processing-started', { input });
      
      const result = await this.doProcessing(input);
      
      this.emit('processing-complete', { result });
      return result;
      
    } catch (error) {
      this.emit('error', error);
      throw error;
    }
  }
  
  private async doProcessing(input: any): Promise<NewComponentResult> {
    // Implementation
  }
}

export function createNewComponent(config: NewComponentConfig): NewComponent {
  return new NewComponent(config);
}
```text


---

## License


The Context Engine is part of Context Sync and is released under the MIT License.

## Support



- **GitHub Issues**: [Report bugs and request features](https://github.com/yourusername/context-sync/issues)

- **Discussions**: [Community discussions and questions](https://github.com/yourusername/context-sync/discussions)  

- **Documentation**: [Full documentation site](https://context-sync.dev/docs)

---

*The Context Engine represents the future of AI-assisted development - where context management is invisible, intelligent, and effortless.*
